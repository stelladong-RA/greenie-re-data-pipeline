Greenie Re â€“ Automated MGA/Carrier Data Pipeline

End-to-end ingestion, quality checks, ZIPâ†’tract mapping, CEJST/LIDAC eligibility scoring, accounting journal entry generation, and ZIP accumulation analytics.

â¸»

ğŸ“Œ Overview

This repository implements the Phase 1 automated data pipeline for Wenhua Zhangâ€™s MGA/carrier program.
It processes raw carrier bordereaux files, validates them, normalizes key financial fields, enriches each project with geographic indicators (ZIP â†’ county â†’ tract), evaluates CEJST/LIDAC eligibility, generates Intacct-ready journal entries, and produces ZIP accumulation reports.

The pipeline is fully modular and built in 8 sequential steps, each producing clean, traceable output in versioned folders (output_stepX/).

It uses a centralized Schema Registry and Data Quality Framework to guarantee consistency across all steps.

â¸»

ğŸ§± Pipeline Architecture (8 Steps)

Step 1 â€” Intake & Data Quality
    â€¢    Reads raw carrier bordereaux from /raw/
    â€¢    Detects file format (.xlsx / .csv)
    â€¢    Applies schema normalization rules
    â€¢    Validates required columns, numeric formats, date fields
    â€¢    Flags anomalies (missing values, invalid types, unknown carriers)

Outputs:
    â€¢    output_step1/silver_intake_parsed.csv
    â€¢    output_step1/exceptions_step1_quality.csv

â¸»

Step 2 â€” Extraction & Normalization
    â€¢    Casts all numeric/date fields using Schema Registry (schema_registry.py)
    â€¢    Standardizes column names across different carriers
    â€¢    Normalizes premium, commission, QS%, dates, addresses
    â€¢    Attaches metadata (source_file, ingestion_timestamp)

Outputs:
    â€¢    output_step2/silver_project_records.csv
    â€¢    output_step2/exceptions_step2_normalization.csv

â¸»

Step 3 â€” ZIP Extraction & Validation
    â€¢    Extracts ZIP code from any free-form address string
    â€¢    Pads ZIP to 5 digits (0211 â†’ 00211)
    â€¢    Validates against HUD ZIP list
    â€¢    Flags invalid or missing ZIPs

Outputs:
    â€¢    output_step3/silver_project_with_zip.csv
    â€¢    output_step3/exceptions_step3_zip_issues.csv

â¸»

Step 4 â€” ZIP â†’ Census Tract Mapping

Uses HUD ZIP-to-tract crosswalk (config/external_data/hud_zip_tract_crosswalk.csv) to compute:
    â€¢    state FIPS
    â€¢    county FIPS
    â€¢    census tract FIPS

Selects tract with highest residential ratio per ZIP.

Outputs:
    â€¢    output_step4/silver_location_enriched.csv
    â€¢    output_step4/exceptions_step4_tract_mapping.csv

â¸»

Step 5 â€” CEJST / LIDAC Eligibility Scoring

Using CEJST v2 dataset (config/external_data/cejst_v2_communities.csv), pipeline:
    â€¢    Joins projects by census tract FIPS
    â€¢    Determines whether tract qualifies as disadvantaged
    â€¢    Computes LIDAC eligibility + reason string

Outputs:
    â€¢    output_step5/gold_lidac_classified.csv
    â€¢    output_step5/exceptions_step5_missing_cejst_match.csv

â¸»

Step 6 â€” Journal Entry Mapping (Intacct)

Converts each project into accounting-ready line items:
    â€¢    Gross premium
    â€¢    Net premium
    â€¢    Commission
    â€¢    Ceded commission
    â€¢    Penal amount
    â€¢    Tract & ZIP metadata
    â€¢    LIDAC eligibility fields

Outputs:
    â€¢    output_step6/gold_journal_entries_for_intacct.csv
    â€¢    output_step6/exceptions_step6_journal_mapping.csv

â¸»

Step 7 â€” ZIP Accumulation Analysis

Aggregates exposure by ZIP:
    â€¢    Project count
    â€¢    Carriers involved
    â€¢    Total gross premium
    â€¢    Total penal amount
    â€¢    Auto-classification (Green / Yellow / Red)

Outputs:
    â€¢    output_step7/gold_zip_accumulation_flags.csv
    â€¢    output_step7/exceptions_step7_missing_zip_or_premium.csv

â¸»

Step 8 â€” Phase 1 Final Output Packaging

Assembles all key stakeholder deliverables:
    â€¢    Intacct export
    â€¢    LIDAC eligibility report
    â€¢    ZIP accumulation report
    â€¢    Exceptions summary across all steps

Outputs:
    â€¢    output_step8/phase1_intacct_export.csv
    â€¢    output_step8/phase1_lidac_report.csv
    â€¢    output_step8/phase1_zip_accumulation.csv
    â€¢    output_step8/phase1_exceptions_summary.csv

â¸»

ğŸ“‚ Folder Structure

greenie-re-data-pipeline/
â”‚
â”œâ”€â”€ raw/                          # Source carrier files (.xlsx, .csv)
â”‚   â”œâ”€â”€ C001_20251201_bordereaux.xlsx
â”‚   â”œâ”€â”€ C002_20251201_bordereaux.xlsx
â”‚   â””â”€â”€ C003_20251201_bordereaux.xlsx
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ schema_registry.py        # Central schema + dtypes
â”‚   â”œâ”€â”€ generate_data.py          # Fake data generator (optional)
â”‚   â”œâ”€â”€ download_hud_zip_tract_crosswalk.py
â”‚   â””â”€â”€ external_data/
â”‚       â”œâ”€â”€ cejst_v2_communities.csv
â”‚       â””â”€â”€ hud_zip_tract_crosswalk.csv
â”‚
â”œâ”€â”€ output_step1/ ... output_step8/
â”‚                               # Each step's silver/gold outputs + exceptions
â”‚
â”œâ”€â”€ doc/
â”‚   â”œâ”€â”€ Phase1_Architecture.tex  # LaTeX technical architecture document
â”‚   â”œâ”€â”€ Phase1_Architecture.pdf
â”‚   â””â”€â”€ diagram assets
â”‚
â”œâ”€â”€ step1_intake_and_quality.py
â”œâ”€â”€ step2_extraction_normalization.py
â”œâ”€â”€ step3_zip_extraction.py
â”œâ”€â”€ step4_zip_to_tract_mapping.py
â”œâ”€â”€ step5_lidac_eligibility_cejst.py
â”œâ”€â”€ step6_journal_entry_mapping.py
â”œâ”€â”€ step7_zip_accumulation.py
â””â”€â”€ step8_phase1_outputs.py


â¸»

â–¶ï¸ How to Run the Pipeline

1. Install dependencies

conda create -n greenie python=3.10
conda activate greenie
pip install -r requirements.txt

If requirements.txt does not exist, generate it:

pip freeze > requirements.txt


â¸»

2. Place carrier raw files

Place all provided bordereaux files into:

raw/


â¸»

3. Run all steps sequentially

You may run each step individually:

python step1_intake_and_quality.py
python step2_extraction_normalization.py
python step3_zip_extraction.py
python step4_zip_to_tract_mapping.py
python step5_lidac_eligibility_cejst.py
python step6_journal_entry_mapping.py
python step7_zip_accumulation.py
python step8_phase1_outputs.py


â¸»

4. Final Deliverables

After Step 8, all Phase-1 outputs are located in:

output_step8/


â¸»

ğŸ“¥ Expected Inputs

Raw files (raw/)
    â€¢    One or more carrier bordereaux files
    â€¢    Supported formats:
    â€¢    .xlsx
    â€¢    .csv
    â€¢    Must contain a project record table with:
    â€¢    Premium fields
    â€¢    Dates
    â€¢    Addresses for ZIP extraction
    â€¢    Broker / obligee fields
    â€¢    Carrier metadata

â¸»

ğŸ“¤ Pipeline Outputs (Business Deliverables)

Output File    Description
phase1_intacct_export.csv    Intacct journal entries
phase1_lidac_report.csv    LIDAC eligibility report
phase1_zip_accumulation.csv    ZIP accumulation + red/yellow/green flags
phase1_exceptions_summary.csv    Cross-step exception logging


â¸»

âš™ï¸ Dependencies
    â€¢    Python 3.10+
    â€¢    pandas
    â€¢    numpy
    â€¢    openpyxl (Excel support)
    â€¢    requests (HUD downloads)
    â€¢    python-dateutil
    â€¢    tqdm

(Optional)
    â€¢    jupyter
    â€¢    matplotlib

â¸»

ğŸ§ª Testing & Validation

Unit tests (future roadmap):

tests/
  â”œâ”€â”€ test_schema_registry.py
  â”œâ”€â”€ test_zip_parsing.py
  â”œâ”€â”€ test_cejst_matching.py
  â””â”€â”€ test_journal_mapping.py


â¸»

ğŸ“˜ Additional Documentation Included

Located in /doc/:
    â€¢    Phase1_Architecture.pdf
Full system architecture diagram (TikZ)
    â€¢    Phase1_Architecture.tex
LaTeX source with diagram + technical narrative

â¸»

ğŸš€ Roadmap (Phase 2+)
    â€¢    API layer for automated ingestion
    â€¢    Deployment on AWS Lambda / ECS
    â€¢    Scheduled runs via Airflow / Prefect
    â€¢    UI dashboard for ZIP + LIDAC visualization
    â€¢    Carrier-specific schema auto-detection
    â€¢    Automated report emailing

â¸»

ğŸ“„ License

To be added once client delivery terms are finalized.
(Default is Proprietary â€“ Not for Redistribution)

â¸»

ğŸ¤ Contact

Greenie Re / Reinsurance Analytics
ğŸ“§ stella.dong@reinsuranceanalytics.io

